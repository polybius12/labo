{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0371cdf5-1dc1-4c99-ba3f-27c078867307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8672206-ff69-47c9-814f-4b895410de9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../buckets/b1/exp/TS5410/dataset_training.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80bbcda-0924-44b4-a7d9-9b6f2c03e7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['clase_ternaria'].replace({'CONTINUA':0, 'BAJA+2':1, 'BAJA+1':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14e8fd4d-1e85-44fb-92e3-7c461dac3464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def undersample_majority(df, target_column):\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_undersampled, y_undersampled = rus.fit_resample(df.drop(target_column, axis=1), df[target_column])\n",
    "    df_undersampled = pd.DataFrame(X_undersampled, columns=df.columns.drop(target_column))\n",
    "    df_undersampled[target_column] = y_undersampled\n",
    "    return df_undersampled\n",
    "\n",
    "def rolling_window_df(df, window_size=0.3, step_size=0.10, max_datasets=6):\n",
    "    num_cols = len(df.columns)\n",
    "    window_cols = int(num_cols * window_size)\n",
    "    step_cols = int(num_cols * step_size)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for start_col in range(0, num_cols, step_cols):\n",
    "        if max_datasets and len(result) >= max_datasets:\n",
    "            break\n",
    "            \n",
    "        end_col = start_col + window_cols\n",
    "        if end_col > num_cols:\n",
    "            break\n",
    "            \n",
    "        result.append(df.iloc[:, start_col:end_col])        \n",
    "    return result\n",
    "\n",
    "\n",
    "def lgb_objective(trial):\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'custom',\n",
    "        'first_metric_only': True,\n",
    "        'boost_from_average': True,\n",
    "        'feature_pre_filter': False,\n",
    "        'force_row_wise': True,\n",
    "        'verbosity': -100,\n",
    "        'max_depth': -1,\n",
    "        'min_gain_to_split': 0.0,\n",
    "        'min_sum_hessian_in_leaf': 0.001,\n",
    "        'lambda_l1': 0.0,\n",
    "        'lambda_l2': 0.0,\n",
    "        'max_bin': 31,\n",
    "        'num_iterations': 9999,\n",
    "        'bagging_fraction': 1.0,\n",
    "        'pos_bagging_fraction': 1.0,\n",
    "        'neg_bagging_fraction': 1.0,\n",
    "        'is_unbalance': False,\n",
    "        'scale_pos_weight': 1.0,\n",
    "        'drop_rate': 0.1,\n",
    "        'max_drop': 50,\n",
    "        'skip_drop': 0.5,\n",
    "        'extra_trees': True,\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.01, 1.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 1024),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 1, 50000),\n",
    "    }\n",
    "\n",
    "    scores = cross_val_score(lgb.LGBMClassifier(**params), X, y, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "def etc_objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 15),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0),\n",
    "    }\n",
    "\n",
    "    scores = cross_val_score(ExtraTreesClassifier(**params), X, y, cv=5, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def experiments(X, y, seeds):\n",
    "    results_df = pd.DataFrame(columns=['seed', 'model', 'training_time', 'f1_score', 'mcc', 'auc', 'custom_metric'])\n",
    "\n",
    "    for seed in seeds:    \n",
    "        np.random.seed(seed)\n",
    "\n",
    "        start_time = time.time()\n",
    "        lgb_study = optuna.create_study(direction='maximize')\n",
    "        lgb_study.optimize(lgb_objective, n_trials=50)\n",
    "        lgb_model = lgb.LGBMClassifier(**lgb_study.best_params)\n",
    "        lgb_model.fit(X, y)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    " \n",
    "        y_pred = lgb_model.predict(X)\n",
    "        results_df = results_df.append({\n",
    "            'seed': seed,\n",
    "            'model': 'LightGBM',\n",
    "            'training_time': training_time,\n",
    "            'f1_score': f1_score(y, y_pred),\n",
    "            'mcc': matthews_corrcoef(y, y_pred),\n",
    "            'auc': roc_auc_score(y, lgb_model.predict_proba(X)[:, 1]),\n",
    "            'custom_metric': custom_metric(y, y_pred)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "      \n",
    "        start_time = time.time()\n",
    "        etc_study = optuna.create_study(direction='maximize')\n",
    "        etc_study.optimize(etc_objective, n_trials=50)\n",
    "        etc_model = ExtraTreesClassifier(**etc_study.best_params)\n",
    "        etc_model.fit(X, y)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "      \n",
    "        y_pred = etc_model.predict(X)\n",
    "        results_df = results_df.append({\n",
    "            'seed': seed,\n",
    "            'model': 'ExtraTrees',\n",
    "            'training_time': training_time,\n",
    "            'f1_score': f1_score(y, y_pred),\n",
    "            'mcc': matthews_corrcoef(y, y_pred),\n",
    "            'auc': roc_auc_score(y, etc_model.predict_proba(X)[:, 1]),\n",
    "            'custom_metric': custom_metric(y, y_pred)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "        \n",
    "        start_time = time.time()\n",
    "        etc_model_default = ExtraTreesClassifier(random_state=seed)\n",
    "        etc_model_default.fit(X, y)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "  \n",
    "        y_pred = etc_model_default.predict(X)\n",
    "        results_df = results_df.append({\n",
    "            'seed': seed,\n",
    "            'model': 'ExtraTreesDefault',\n",
    "            'training_time': training_time,\n",
    "            'f1_score': f1_score(y, y_pred),\n",
    "            'mcc': matthews_corrcoef(y, y_pred),\n",
    "            'auc': roc_auc_score(y, etc_model_default.predict_proba(X)[:, 1]),\n",
    "            'custom_metric': custom_metric(y, y_pred)\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8d3be56-7341-4a1e-83f4-6e14fa2aea2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16926/2178908092.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_undersampled[target_column] = y_undersampled\n"
     ]
    }
   ],
   "source": [
    "df_undersampled = undersample_majority(df, 'clase_ternaria')\n",
    "\n",
    "train_data = df_undersampled[df_undersampled['fold_test'] !=1]\n",
    "test_data = df_undersampled[df_undersampled['fold_test'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1b47a1-f7e9-45bd-901c-45f998bbf375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data = df[df['fold_test'] !=1]\n",
    "# test_data = df[df['fold_test'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42b25db-deae-425b-8c1c-680abf8a3793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(columns='clase_ternaria')\n",
    "y = train_data['clase_ternaria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176de839-b432-4c66-9454-9c55331a3dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d29abdf2-1621-4bcc-b6f7-aa66ba5f674e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_model.fit(X, y)\n",
    "importances_lgbm = lgbm_model.feature_importances_\n",
    "feature_importances_df = pd.DataFrame({'feature': X.columns, 'importance': importances_lgbm})\n",
    "feature_importances_df.sort_values('importance', ascending=False, inplace=True)\n",
    "X.columns = feature_importances_df['feature'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9be59-b1de-496d-89e2-15540d95febc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df40e579-3717-4c24-93af-3f49b0ff4755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## datasets\n",
    "dataset_1 = X.iloc[:,:int(X.shape[1]*0.3)]\n",
    "dataset_2 = X.iloc[:,int(X.shape[1]*0.6):]\n",
    "dataset_3 = X[random.sample(X.columns.to_list(), k=int(X.shape[1]*0.3))]\n",
    "\n",
    "dataset_rolling = rolling_window_df(X)\n",
    "dataset_4 = dataset_rolling[1]\n",
    "dataset_5 = dataset_rolling[2]\n",
    "dataset_6 = dataset_rolling[3]\n",
    "dataset_7 = dataset_rolling[4]\n",
    "dataset_8 = dataset_rolling[5]\n",
    "\n",
    "dataset_9 = pd.concat([X.iloc[:,:int(X.shape[1]*0.15)],X.iloc[:,int(X.shape[1]*0.85):]])\n",
    "dataset_10 = X[list(set(X.columns) - set(dataset_9.columns))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10433c59-d613-46f2-b162-ab1e614ec957",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7f8744-8d97-4bf2-8fdb-f45837e8d804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90d4f7eb-c4b7-46a0-bfb5-68892f3f19a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [677213, 727817, 311237, 660719, 106427]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66797866-6c8a-4044-9fe4-390d97473ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-19 14:33:30,873]\u001b[0m A new study created in memory with name: no-name-846faa70-c1d6-435c-a9c6-4122f8136ee9\u001b[0m\n",
      "/tmp/ipykernel_16926/505427659.py:27: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
      "/tmp/ipykernel_16926/505427659.py:28: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'feature_fraction': trial.suggest_uniform('feature_fraction', 0.01, 1.0),\n",
      "/home/estebanelia/.local/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/home/estebanelia/.local/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2842374057608392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2842374057608392\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5520, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5520\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estebanelia/.local/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2842374057608392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2842374057608392\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5520, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5520\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estebanelia/.local/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2842374057608392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2842374057608392\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5520, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5520\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estebanelia/.local/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2842374057608392, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2842374057608392\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5520, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5520\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    }
   ],
   "source": [
    "results_experiment_1 = experiments(dataset_1, y, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b965d7-9925-41b1-b3f7-b5464c42ebba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
